{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick training playground for autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras import models, layers, applications, backend as K\n",
    "from tensorflow.keras.losses import MeanSquaredError, KLDivergence\n",
    "from plotly import express as px\n",
    "\n",
    "# Load dataset\n",
    "(x_train, _), (x_test, _) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "\n",
    "input_img = layers.Input(shape=(28, 28, 1))\n",
    "\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "encoded = layers.Dense(2, activation='sigmoid')(x)\n",
    "\n",
    "# Build the encoder\n",
    "encoder = models.Model(input_img, encoded, name='encoder')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "input_latent = layers.Input(shape=(2,))\n",
    "\n",
    "x = layers.Dense(7 * 7 * 128, activation='relu')(input_latent)\n",
    "\n",
    "x = layers.Reshape((7, 7, 128))(x)\n",
    "\n",
    "# Decoder with skip connections\n",
    "x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "\n",
    "# Add the first skip connection from the encoder\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "\n",
    "\n",
    "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "\n",
    "# Add the second skip connection from the encoder\n",
    "x = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "# Build the decoder\n",
    "decoder = models.Model(input_latent, x, name='decoder')\n",
    "\n",
    "# Build the autoencoder\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = models.Model(inputs = input_img, outputs = [decoder(encoder(input_img)), encoder(input_img)])\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def density_loss(z_true, z_pred, radius=0.05): \n",
    "    distances = tf.norm(z_pred[:, tf.newaxis, :] - z_pred, axis=2)\n",
    "    num_neighbors = tf.reduce_sum(tf.cast(distances < radius, tf.float32), axis=1)\n",
    "    density = tf.reduce_mean(num_neighbors)\n",
    "    return density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(x_true, x_pred): \n",
    "    mse = tf.reduce_mean(tf.square(x_true - x_pred))\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular optimizer\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "# Compile using two losses\n",
    "autoencoder.compile(optimizer=opt, loss=[mse_loss, density_loss], loss_weights=[1.0, 0.001])\n",
    "\n",
    "# Callbacks\n",
    "early_stop_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='checkpoint_autoencoder.h5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "# Train the model\n",
    "history = autoencoder.fit(\n",
    "    x_train,\n",
    "    [x_train, x_train],\n",
    "    epochs=75,\n",
    "    batch_size=256,\n",
    "    validation_data=(x_test, [x_test, x_test]),\n",
    "    callbacks = [checkpoint_cb, early_stop_cb],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {k:v for k,v in history.history.items()}\n",
    "fig = px.line(pd.DataFrame(d))\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Evaluate encoder mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train = encoder.predict(x_train)\n",
    "preds_test = encoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(pd.DataFrame(preds_test), x=0,y=1)\n",
    "fig.update_yaxes(scaleanchor = \"x\", scaleratio = 1)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(pd.DataFrame(preds_train), x=0,y=1)\n",
    "fig.update_yaxes(scaleanchor = \"x\", scaleratio = 1)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Save best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.save('saved_models/best_encoder.h5')\n",
    "decoder.save('saved_models/best_decoder.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hja_py38tf28",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
